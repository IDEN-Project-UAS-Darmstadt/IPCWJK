% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ipcw_xgboost.R
\name{ipcw_xgboost}
\alias{ipcw_xgboost}
\alias{ipcw_xgboost_default_grid}
\title{IPCW XGBoost Binary Classifier}
\usage{
ipcw_xgboost(
  data,
  tau,
  time_var = "t",
  status_var = "delta",
  verbose = 0,
  grid = ipcw_xgboost_default_grid(),
  nrounds = 100,
  early_stopping_rounds = 10,
  nfold = 3,
  nthread = 1
)

ipcw_xgboost_default_grid()
}
\arguments{
\item{data}{A data frame containing the survival data. Must include columns
for the observed time and event indicator.}

\item{tau}{Numeric scalar. The time horizon at which the survival
probability is to be estimated.}

\item{time_var}{Character. The name of the variable in \code{data}
representing the observed time to event or censoring.
Default is \code{"t"}.}

\item{status_var}{Character. The name of the variable in \code{data}
representing the event indicator (1 if event occurred, 0 if censored).
Default is \code{"delta"}.}

\item{verbose}{Integer. Verbosity level for XGBoost training and
cross-validation (default is 0).}

\item{grid}{Data frame. Grid of hyperparameters to test in cross-validation.
The default is the output of \code{ipcw_xgboost_default_grid()}.}

\item{nrounds}{Integer. Maximum number of boosting rounds for XGBoost
training and cross-validation (default is 100).}

\item{early_stopping_rounds}{Integer. Number of rounds with no improvement
to trigger early stopping during cross-validation (default is 10).}

\item{nfold}{Integer. Number of folds for cross-validation (default is 3).}

\item{nthread}{Integer. Number of threads to use for XGBoost training
(default is 1).}
}
\value{
An object of class \code{IPCWModel}.
}
\description{
\loadmathjax
Fits a binary classification model using XGBoost with IPCW for
right-censored survival data. Hyperparameter tuning and Jackknife
model training are performed.
}
\details{
Training is performed using the \code{xgboost} package
\insertCite{xgboost}{IPCWJK}. The weights are calculated using the
}
\section{Functions}{
\itemize{
\item \code{ipcw_xgboost_default_grid()}: Returns a default grid of hyperparameters.

}}
\examples{
#' # veteran data example
library(survival)
tau <- 80
df <- veteran[, c("time", "status", "trt")]
newdata <- data.frame(trt = c(1, 2))

fit <- ipcw_xgboost(df,
  tau = tau, time_var = "time",
  status_var = "status"
)
predict(fit, newdata)
}
\references{
\insertAllCited{}
}
\seealso{
\code{\link{ipcw_weights}} function, and then normalized to sum
to one.

Hyperparameter tuning is performed using three fold cross-validation with a
grid of parameters. The best parameters are selected based on the minimum
test log loss over 100 rounds with early stopping (10 rounds).
Note that the tested hyperparameters are
based on our simulations study and may not be optimal for all datasets.

The tested hyperparameters include:
\itemize{
\item \code{booster}: "gbtree" or "gblinear". For "gbtree":
\item \code{eta}: Learning rate, tested as \code{1 / 10^(0:5)}.
\item \code{max_depth}: Maximum depth of the tree, tested as \code{c(12, 6, 3, 1)}.
}

With the best parameters, the model is trained on the full dataset.

Other ipcwmodels: 
\code{\link{ipcw_logistic_regression}()}
}
\concept{ipcwmodels}
